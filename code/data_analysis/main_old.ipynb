{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Downloading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "cwd = os.getcwd()\n",
    "fp_data = os.path.join(cwd, \"../../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/wojciechrokicki/.kaggle/kaggle.json'\n",
      "Downloading creditcardfraud.zip to /Users/wojciechrokicki/Documents/Magister/praca_magisterska/active-learning-analysis/code/data_analysis\n",
      "100%|██████████████████████████████████████| 66.0M/66.0M [00:37<00:00, 1.10MB/s]\n",
      "100%|██████████████████████████████████████| 66.0M/66.0M [00:37<00:00, 1.85MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Credit Fraud https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "# In order to work, you need to pip install kaggle and have kaggle account, download API key, place it in ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download mlg-ulb/creditcardfraud\n",
    "os.rename(\"creditcardfraud.zip\", fp_data + \"creditcardfraud.zip\")\n",
    "# Heart Disease https://sci2s.ugr.es/keel/dataset.php?cod=980\n",
    "wget.download(\"https://sci2s.ugr.es/keel/dataset/data/imbalanced/cleveland-0_vs_4.zip\")\n",
    "os.rename(\"cleveland-0_vs_4.zip\", fp_data + \"cleveland-0_vs_4.zip\")\n",
    "# Space Shuttle https://sci2s.ugr.es/keel/dataset.php?cod=125\n",
    "wget.download(\"https://sci2s.ugr.es/keel/dataset/data/imbalanced/shuttle-c0-vs-c4.zip\")\n",
    "os.rename(\"shuttle-c0-vs-c4.zip\", fp_data + \"shuttle-c0-vs-c4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_credit_card_fraud = pd.read_csv(os.path.join(fp_data, \"creditcardfraud.zip\"), compression=\"zip\", sep=\",\")\n",
    "df_credit_card_fraud.rename(columns={\"Class\": \"class\"}, inplace=True)\n",
    "display(df_credit_card_fraud.shape)\n",
    "display(df_credit_card_fraud.head())\n",
    "display(df_credit_card_fraud.describe())\n",
    "display(df_credit_card_fraud.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>testecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  testecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "2  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "3  56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
       "4  57.0  0.0  4.0     120.0  354.0  0.0      0.0    163.0    1.0      0.6   \n",
       "\n",
       "   slope   ca thal     class  \n",
       "0    3.0  0.0  6.0  negative  \n",
       "1    3.0  0.0  3.0  negative  \n",
       "2    1.0  0.0  3.0  negative  \n",
       "3    1.0  0.0  3.0  negative  \n",
       "4    1.0  0.0  3.0  negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>testecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.107345</td>\n",
       "      <td>0.581921</td>\n",
       "      <td>2.858757</td>\n",
       "      <td>129.949153</td>\n",
       "      <td>243.429379</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>157.073446</td>\n",
       "      <td>0.163842</td>\n",
       "      <td>0.716949</td>\n",
       "      <td>1.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.659240</td>\n",
       "      <td>0.494643</td>\n",
       "      <td>0.939865</td>\n",
       "      <td>16.417587</td>\n",
       "      <td>54.350994</td>\n",
       "      <td>0.343327</td>\n",
       "      <td>0.991327</td>\n",
       "      <td>19.746410</td>\n",
       "      <td>0.371182</td>\n",
       "      <td>0.953430</td>\n",
       "      <td>0.612058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  177.000000  177.000000  177.000000  177.000000  177.000000  177.000000   \n",
       "mean    53.107345    0.581921    2.858757  129.949153  243.429379    0.135593   \n",
       "std      9.659240    0.494643    0.939865   16.417587   54.350994    0.343327   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     45.000000    0.000000    2.000000  120.000000  209.000000    0.000000   \n",
       "50%     53.000000    1.000000    3.000000  130.000000  234.000000    0.000000   \n",
       "75%     60.000000    1.000000    4.000000  140.000000  269.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  180.000000  564.000000    1.000000   \n",
       "\n",
       "          testecg     thalach       exang     oldpeak       slope  \n",
       "count  177.000000  177.000000  177.000000  177.000000  177.000000  \n",
       "mean     0.892655  157.073446    0.163842    0.716949    1.457627  \n",
       "std      0.991327   19.746410    0.371182    0.953430    0.612058  \n",
       "min      0.000000   96.000000    0.000000    0.000000    1.000000  \n",
       "25%      0.000000  146.000000    0.000000    0.000000    1.000000  \n",
       "50%      0.000000  160.000000    0.000000    0.300000    1.000000  \n",
       "75%      2.000000  172.000000    0.000000    1.200000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    4.400000    3.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177 entries, 0 to 176\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       177 non-null    float64\n",
      " 1   sex       177 non-null    float64\n",
      " 2   cp        177 non-null    float64\n",
      " 3   trestbps  177 non-null    float64\n",
      " 4   chol      177 non-null    float64\n",
      " 5   fbs       177 non-null    float64\n",
      " 6   testecg   177 non-null    float64\n",
      " 7   thalach   177 non-null    float64\n",
      " 8   exang     177 non-null    float64\n",
      " 9   oldpeak   177 non-null    float64\n",
      " 10  slope     177 non-null    float64\n",
      " 11  ca        177 non-null    object \n",
      " 12  thal      177 non-null    object \n",
      " 13  class     177 non-null    object \n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 19.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hd_names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"testecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"class\"]\n",
    "df_heart_disease = pd.read_csv(os.path.join(fp_data, \"cleveland-0_vs_4.zip\"), compression='zip', header=None, names=hd_names, sep=',', skiprows=18)\n",
    "display(df_heart_disease.shape)\n",
    "display(df_heart_disease.head())\n",
    "display(df_heart_disease.describe())\n",
    "display(df_heart_disease.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>-5</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>-4</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>-10</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9     class\n",
       "0  49   0  79   0  46  -5  30  32   2  negative\n",
       "1  41   1  86   3  42   6  45  45   0  negative\n",
       "2  50  -4  83   0  50   0  33  34   2  negative\n",
       "3  48   1  81  -1  46   0  33  34   2  negative\n",
       "4  45   0  86   0  44 -10  41  42   2  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.782941</td>\n",
       "      <td>0.427009</td>\n",
       "      <td>85.466922</td>\n",
       "      <td>1.179333</td>\n",
       "      <td>37.127392</td>\n",
       "      <td>3.929470</td>\n",
       "      <td>38.692182</td>\n",
       "      <td>48.374522</td>\n",
       "      <td>9.817387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.177895</td>\n",
       "      <td>39.810392</td>\n",
       "      <td>9.212280</td>\n",
       "      <td>61.702120</td>\n",
       "      <td>21.351586</td>\n",
       "      <td>150.539976</td>\n",
       "      <td>13.908770</td>\n",
       "      <td>22.124850</td>\n",
       "      <td>24.525330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>-908.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>-587.000000</td>\n",
       "      <td>-46.000000</td>\n",
       "      <td>-898.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>-353.000000</td>\n",
       "      <td>-356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>1409.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>2565.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>6339.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A1           A2           A3           A4           A5  \\\n",
       "count  1829.000000  1829.000000  1829.000000  1829.000000  1829.000000   \n",
       "mean     46.782941     0.427009    85.466922     1.179333    37.127392   \n",
       "std      13.177895    39.810392     9.212280    61.702120    21.351586   \n",
       "min      36.000000  -908.000000    74.000000  -587.000000   -46.000000   \n",
       "25%      37.000000     0.000000    79.000000     0.000000    34.000000   \n",
       "50%      44.000000     0.000000    83.000000     0.000000    42.000000   \n",
       "75%      49.000000     0.000000    88.000000     0.000000    46.000000   \n",
       "max     123.000000  1409.000000   113.000000  2565.000000   436.000000   \n",
       "\n",
       "                A6           A7           A8           A9  \n",
       "count  1829.000000  1829.000000  1829.000000  1829.000000  \n",
       "mean      3.929470    38.692182    48.374522     9.817387  \n",
       "std     150.539976    13.908770    22.124850    24.525330  \n",
       "min    -898.000000   -18.000000  -353.000000  -356.000000  \n",
       "25%      -4.000000    33.000000    35.000000     0.000000  \n",
       "50%       0.000000    39.000000    41.000000     2.000000  \n",
       "75%       5.000000    43.000000    57.000000     6.000000  \n",
       "max    6339.000000    72.000000   130.000000   126.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1829 entries, 0 to 1828\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   A1      1829 non-null   int64 \n",
      " 1   A2      1829 non-null   int64 \n",
      " 2   A3      1829 non-null   int64 \n",
      " 3   A4      1829 non-null   int64 \n",
      " 4   A5      1829 non-null   int64 \n",
      " 5   A6      1829 non-null   int64 \n",
      " 6   A7      1829 non-null   int64 \n",
      " 7   A8      1829 non-null   int64 \n",
      " 8   A9      1829 non-null   int64 \n",
      " 9   class   1829 non-null   object\n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 143.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss_names = [\"A\"+str(i+1) for i in range(9)]\n",
    "ss_names.append(\"class\")\n",
    "df_space_shuttle = pd.read_csv(os.path.join(fp_data, \"shuttle-c0-vs-c4.zip\"), compression=\"zip\", header=None, names=ss_names, sep=\",\", skiprows=14)\n",
    "display(df_space_shuttle.shape)\n",
    "display(df_space_shuttle.head())\n",
    "display(df_space_shuttle.describe())\n",
    "display(df_space_shuttle.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessig datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = [\n",
    "    # df_credit_card_fraud, \n",
    "    df_heart_disease,\n",
    "    df_space_shuttle\n",
    "]\n",
    "\n",
    "def get_variable_name(variable):\n",
    "    ''' Function for getting variable name. '''\n",
    "    globals_dict = globals()\n",
    "    return [var_name for var_name in globals_dict if globals_dict[var_name] is variable]\n",
    "\n",
    "# Checking if there are any NaNs\n",
    "def check_df_for_nans(df: pd.DataFrame):\n",
    "    assert df.isna().sum().any() == False, f\"There are some NaNs in {get_variable_name(df)}\"\n",
    "\n",
    "_ = [check_df_for_nans(dataset) for dataset in all_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorizing datasets classes\n",
    "def factorize_df_class(df: pd.DataFrame, class_column: str=\"class\"):\n",
    "    ''' Converts categorical variable to numeric and returns dataframe and maping for classes '''\n",
    "    factorized_classes = pd.factorize(df[class_column])\n",
    "    df[class_column] = factorized_classes[0]\n",
    "    return df, factorized_classes[1]\n",
    "\n",
    "all_datasets, all_datasets_class_indexes = list(zip(*[factorize_df_class(dataset) for dataset in all_datasets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df_heart_disease[\"class\"].unique() == np.array([0,1])).all() == True, \"Binary factorizing not correct!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorizing other columns\n",
    "def factorize_df_columns(df: pd.DataFrame):\n",
    "    ''' Converts object dtypes to numeric and returns dataframe and mapings for columns '''\n",
    "    df_object_dtypes = df.select_dtypes(include=\"object\")\n",
    "    factorizations = []\n",
    "    for col in df_object_dtypes.columns:\n",
    "        factorized_values = pd.factorize(df_object_dtypes[col])\n",
    "        df[col] = factorized_values[0]\n",
    "        factorizations.append(factorized_values[1])\n",
    "    return df, factorizations\n",
    "\n",
    "df_heart_disease, df_heart_disease_columns_indexes = factorize_df_columns(df_heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Analysing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for df_credit_card_fraud: \n",
      "0    284315\n",
      "1       492\n",
      "Name: class, dtype: int64\n",
      "Class distribution for df_heart_disease: \n",
      "0    164\n",
      "1     13\n",
      "Name: class, dtype: int64\n",
      "Class distribution for df_space_shuttle: \n",
      "0    1706\n",
      "1     123\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_classes_distribution(df: pd.DataFrame):\n",
    "    print(f\"Class distribution for {get_variable_name(df)[0]}: \")\n",
    "    print(df[\"class\"].value_counts())\n",
    "\n",
    "_ = [check_classes_distribution(df) for df in all_datasets]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Spliting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_pool_test_split(X, y, test_size=0.2, train_size=0.4, random_state=13, verbose=False):\n",
    "    \"\"\"Splits the dataset into train, pool (unlabelled), test sets.\n",
    "\n",
    "    For default parameters dataset will be deivided into 0.2 test, \n",
    "    0.4*0.8=0.32 train and 0.6*0.8=0.48 pool sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "    y : array-like, default=None\n",
    "        The target variable for supervised learning problems.\n",
    "    test_size : float or int, default=0.2\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split from the whole dataset. \n",
    "        If int, represents the absolute number of test samples.\n",
    "    train_size : float or int, default=0.4\n",
    "        Should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the train split from remaining train subset.\n",
    "        If int, represents the absolute number of test samples.\n",
    "    random_state : int, default=13\n",
    "        Controls the shuffling applied to the data before applying the split.\n",
    "        Pass an int for reproducible output across multiple function calls.\n",
    "    verbose: bool, default=False\n",
    "        Variable enriching the output of the function. It prints informations\n",
    "        about splits classes counts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    splitting : list, length=6\n",
    "        List containing train-pool-test split of inputs.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> X_train, X_pool, X_test, y_train, y_pool, y_test = train_pool_test_split(X, y)\n",
    "\n",
    "    \"\"\"\n",
    "    # if type(test_size) == int and type(train_size) == int:\n",
    "    #     if len(X) < test_size + train_size\n",
    "    #     raise ValueError(f'Dataset doesn\\'t have {test_size+train_size} samples.')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_train, X_pool, y_train, y_pool = train_test_split(X_train, y_train, train_size=train_size, random_state=random_state)\n",
    "    if verbose:\n",
    "        def count_unique_classes(y_set: np.array): \n",
    "            unique_counts = np.unique(y_set, return_counts=True)\n",
    "            classes = unique_counts[0].tolist()\n",
    "            counts = unique_counts[1].tolist()\n",
    "            _ = [print(f'There are {counts[idx]} samples of class {c}') for idx, c in enumerate(classes)]\n",
    "        # Train\n",
    "        print(\"Train set:\")\n",
    "        count_unique_classes(y_train)\n",
    "        # Pool\n",
    "        print(\"Pool set:\")\n",
    "        count_unique_classes(y_pool)\n",
    "        # Test\n",
    "        print(\"Train set:\")\n",
    "        count_unique_classes(y_test)\n",
    "\n",
    "    return X_train, X_pool, X_test, y_train, y_pool, y_test\n",
    "\n",
    "train_sizes=[\n",
    "    # 1, 2, 5,\n",
    "    10, 20, 50, 100\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# # predict_proba -> informative samples with smallest probabilities\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# CV suffix for cross-validation, which selects best hyperparameters (roughly equivalent to GridSearchCV(Estimator()))\n",
    "# predict_proba -> informative samples with smallest probabilities\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "# decision_function (distance from the decision boundary) -> informative samples with smallest distance\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# # predict_proba -> informative samples with smallest probabilities\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# predict_proba -> informative samples with smallest probabilities\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# predict_proba -> informative samples with smallest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# Import active learning classes and methods\n",
    "from active_learning.measurements import decision_boundary_most_ambiguous\n",
    "from active_learning.measurements import UncertaintySampling, QueryByCommittee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to json config file?\n",
    "\n",
    "def get_probabilistic_model(m):\n",
    "    probabilistic_models_switcher={\n",
    "        # \"MNB\": {\n",
    "        #     \"model\": MultinomialNB,\n",
    "        #     \"params\": [{}]\n",
    "        # }, \n",
    "        \"LR\": {\n",
    "            \"model\": LogisticRegression,\n",
    "            \"params\": [{}]\n",
    "        },\n",
    "        \"SVC\": {\n",
    "            \"model\": SVC,\n",
    "            \"params\": [{'C': 1.0, 'kernel': 'rbf', 'class_weight': None, 'max_iter': 1000, 'random_state': None, 'probability': True, 'tol': 0.0001, 'verbose': 0}]\n",
    "        },\n",
    "        # \"DTC\": {\n",
    "        #     \"model\": DecisionTreeClassifier,\n",
    "        #     \"params\": [{}]\n",
    "        # },\n",
    "        \"RFC\": {\n",
    "            \"model\": RandomForestClassifier,\n",
    "            \"params\": [{}]\n",
    "        },\n",
    "        \"GBC\": {\n",
    "            \"model\": GradientBoostingClassifier,\n",
    "            \"params\": [{}]\n",
    "        }\n",
    "    }\n",
    "    return probabilistic_models_switcher.get(m, \"Invalid model\")\n",
    "    \n",
    "probabilistic_models=[\n",
    "    # \"MNB\",\n",
    "    # \"LR\", \n",
    "    \"SVC\",\n",
    "    # \"DTC\", \n",
    "    # \"RFC\", \n",
    "    # \"GBC\"\n",
    "]\n",
    "\n",
    "def get_active_learning_method(m):\n",
    "    active_learning_methods_switcher={\n",
    "        \"least_confident\": {\n",
    "            \"method\": UncertaintySampling.least_confident,\n",
    "            \"params\": [{}]\n",
    "        },\n",
    "        \"query_by_committee\":{\n",
    "            \"method\": QueryByCommittee.query,\n",
    "            \"params\":[{'n_models': 5, 'disagreement_measure': 'vote_entropy'}]\n",
    "\n",
    "        }\n",
    "    }\n",
    "    return active_learning_methods_switcher.get(m, \"Invalid method\")\n",
    "\n",
    "\n",
    "active_learning_methods=[\n",
    "    \"least_confident\",\n",
    "    \"query_by_committee\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report # returns prec, rec, accur, f1\n",
    "# output_dict=True \n",
    "# {'label 1': {'precision':0.5,\n",
    "#              'recall':1.0,\n",
    "#              'f1-score':0.67,\n",
    "#              'support':1},\n",
    "#  'label 2': { ... },\n",
    "#   ...\n",
    "# }\n",
    "from sklearn.metrics import auc, precision_recall_curve, roc_curve, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Models evaluation\n",
    "def clf_eval(clf, X_test, y_test): #TODO: parametrizing the output\n",
    "    y_pred = clf.predict(X_test.to_numpy())\n",
    "\n",
    "    # print(\"Classification report for model: \")\n",
    "    # print(classification_report(y_test.values, y_pred, zero_division=0))\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_test, y_pred)\n",
    "    auc_roc_curve = auc(fpr, tpr)\n",
    "\n",
    "    precisions, recalls, pr_thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    auc_pr_curve = auc(recalls, precisions)\n",
    "\n",
    "    # TODO: Check if there are any positive samples in y_test (ensure it!)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    if precision+recall != 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0\n",
    "\n",
    "    return precision, recall, f1_score, auc_pr_curve, auc_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning\n",
    "def learn_active(Clf, clf_params, method_name, alm, alm_params, X_train, X_pool, X_test, y_train, y_pool, y_test, max_iterations): # TODO: Add stop criterions\n",
    "    # Preventing from changing original dataframes\n",
    "    X_pool = X_pool.copy()\n",
    "    y_pool = y_pool.copy()\n",
    "\n",
    "    # print(f\"Initial model: \")\n",
    "    model = Clf(**clf_params)\n",
    "    model.fit(X_train.to_numpy(), y_train.values)\n",
    "    # clf_eval(model, X_test, y_test)\n",
    "\n",
    "    # If QBC, then create committee first, then in each iteration get most informative samples and learn model.\n",
    "    if method_name == \"query_by_committee\":\n",
    "        QueryByCommittee.__init__(X_train, y_train)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        index = alm(model, X_pool, **alm_params)\n",
    "\n",
    "        X_informative = X_pool.loc[index]\n",
    "        X_informative = X_informative.loc[:, ~X_informative.columns.isin([\"pred_proba\", \"max_proba\"])]\n",
    "        X_train = pd.concat([X_train, X_informative])\n",
    "        X_pool.drop(index, inplace=True)\n",
    "\n",
    "        y_informative = y_pool.loc[index]\n",
    "        y_train = pd.concat([y_train, y_informative])\n",
    "        y_pool.drop(index, inplace=True)\n",
    "\n",
    "        # print(f\"Model trained with {i+1} pool samples: \")\n",
    "        model = Clf(**clf_params)\n",
    "        model.fit(X_train.to_numpy(), y_train.values)\n",
    "\n",
    "\n",
    "    return clf_eval(model, X_test, y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Classificator: SVC\n",
      "Classificator parameters: {'C': 1.0, 'kernel': 'rbf', 'class_weight': None, 'max_iter': 1000, 'random_state': None, 'probability': True, 'tol': 0.0001, 'verbose': 0}\n",
      "Active learning method: least_confident\n",
      "Active leraning parameters: {}\n",
      "Dataset: df_heart_disease\n",
      "--------------------------------------------------\n",
      "\n",
      "Precision: 0.40\n",
      "Recall: 0.20\n",
      "F1 score: 0.27\n",
      "Precision-Recall AUC: 0.63\n",
      "ROC AUC: 0.60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojciechrokicki/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-0.32260922  0.50796289 -1.25700284  1.13089197  1.13089197 -0.21878771\n  0.71560591 -0.63407376  0.40414137 -0.9455383  -0.21878771 -1.04935982\n -0.21878771 -0.1149662  -1.98375344  0.09267683  1.23471348 -1.56846738\n  0.09267683 -1.04935982 -1.6722889   1.02707045  0.92324894  0.09267683\n  1.02707045  0.92324894  1.33853499  1.23471348 -1.25700284 -0.84171679\n  1.13089197 -1.87993192 -0.9455383   0.40414137 -1.15318133 -0.1149662\n  0.30031986 -0.1149662  -0.01114468 -0.73789528 -0.1149662  -0.84171679\n  0.09267683 -1.25700284 -1.46464587  1.02707045 -1.04935982 -1.15318133\n  0.50796289 -1.15318133 -1.6722889  -0.1149662   1.23471348  0.30031986\n  0.40414137  0.81942743 -0.42643074  1.85764256 -1.36082436 -1.46464587\n -0.84171679  0.50796289 -0.63407376 -0.32260922  0.6117844   0.6117844\n -1.46464587  1.64999953].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 62\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m# # TODO: reference model trained on train+pool?\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# X_ref = np.concatenate((X_train, X_pool), axis=0)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# y_ref = np.concatenate((y_train, y_pool), axis=0)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m max_iterations \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m# TODO: add as a parameter in al method\u001b[39;00m\n\u001b[1;32m     61\u001b[0m precision, recall, f1_score, auc_pr_curve, auc_roc_curve \u001b[39m=\u001b[39m \\\n\u001b[0;32m---> 62\u001b[0m     learn_active(Clf, clf_params, method_name, alm, alm_params, X_train_init, X_pool, \\\n\u001b[1;32m     63\u001b[0m     X_test_kf, y_train_init, y_pool, y_test_kf, max_iterations)\n\u001b[1;32m     65\u001b[0m precision_arr\u001b[39m.\u001b[39mappend(precision)\n\u001b[1;32m     66\u001b[0m recall_arr\u001b[39m.\u001b[39mappend(recall)\n",
      "Cell \u001b[0;32mIn [13], line 17\u001b[0m, in \u001b[0;36mlearn_active\u001b[0;34m(Clf, clf_params, method_name, alm, alm_params, X_train, X_pool, X_test, y_train, y_pool, y_test, max_iterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m     QueryByCommittee\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(X_train, y_train)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iterations):\n\u001b[0;32m---> 17\u001b[0m     index \u001b[39m=\u001b[39m alm(model, X_pool, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49malm_params)\n\u001b[1;32m     19\u001b[0m     X_informative \u001b[39m=\u001b[39m X_pool\u001b[39m.\u001b[39mloc[index]\n\u001b[1;32m     20\u001b[0m     X_informative \u001b[39m=\u001b[39m X_informative\u001b[39m.\u001b[39mloc[:, \u001b[39m~\u001b[39mX_informative\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39misin([\u001b[39m\"\u001b[39m\u001b[39mpred_proba\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax_proba\u001b[39m\u001b[39m\"\u001b[39m])]\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/code/active_learning/measurements.py:108\u001b[0m, in \u001b[0;36mQueryByCommittee.query\u001b[0;34m(clf, X_pool, n_models, disagreement_measure)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUnknown method of measuring committee disagreement.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m index \u001b[39m=\u001b[39m disagreement_measure_method(X_pool)\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m index\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/code/active_learning/measurements.py:73\u001b[0m, in \u001b[0;36mQueryByCommittee.vote_entropy\u001b[0;34m(X_pool)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m        \n\u001b[1;32m     72\u001b[0m X_pool \u001b[39m=\u001b[39m X_pool\u001b[39m.\u001b[39mloc[:, \u001b[39m~\u001b[39mX_pool\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39misin([\u001b[39m\"\u001b[39m\u001b[39mvote_entropy\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[0;32m---> 73\u001b[0m X_pool[\u001b[39m'\u001b[39m\u001b[39mvote_entropy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X_pool\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x : entropy(x))\n\u001b[1;32m     74\u001b[0m X_pool\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvote_entropy\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m [X_pool\u001b[39m.\u001b[39mindex[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/pandas/core/frame.py:8848\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8837\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8839\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   8840\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   8841\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8846\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   8847\u001b[0m )\n\u001b[0;32m-> 8848\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/pandas/core/apply.py:733\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    731\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/pandas/core/apply.py:857\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 857\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    859\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    871\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    872\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    874\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    875\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    876\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    877\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/code/active_learning/measurements.py:73\u001b[0m, in \u001b[0;36mQueryByCommittee.vote_entropy.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m        \n\u001b[1;32m     72\u001b[0m X_pool \u001b[39m=\u001b[39m X_pool\u001b[39m.\u001b[39mloc[:, \u001b[39m~\u001b[39mX_pool\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39misin([\u001b[39m\"\u001b[39m\u001b[39mvote_entropy\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[0;32m---> 73\u001b[0m X_pool[\u001b[39m'\u001b[39m\u001b[39mvote_entropy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X_pool\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x : entropy(x))\n\u001b[1;32m     74\u001b[0m X_pool\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvote_entropy\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m [X_pool\u001b[39m.\u001b[39mindex[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/code/active_learning/measurements.py:67\u001b[0m, in \u001b[0;36mQueryByCommittee.vote_entropy.<locals>.entropy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     65\u001b[0m votes \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m committee_member \u001b[39min\u001b[39;00m QueryByCommittee\u001b[39m.\u001b[39mcommittee:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mif\u001b[39;00m committee_member\u001b[39m.\u001b[39;49mpredict(x) \u001b[39m==\u001b[39m y_i:\n\u001b[1;32m     68\u001b[0m         votes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[39msum\u001b[39m \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m votes\u001b[39m/\u001b[39mC \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(votes\u001b[39m/\u001b[39mC)\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    819\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    821\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    418\u001b[0m     \u001b[39m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[39m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[1;32m    434\u001b[0m     predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[1;32m    435\u001b[0m     \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:613\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    612\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m--> 613\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    614\u001b[0m         X,\n\u001b[1;32m    615\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    616\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    617\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    618\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    619\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    620\u001b[0m     )\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[1;32m    623\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/Documents/Magister/praca_magisterska/active-learning-analysis/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 900\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    907\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-0.32260922  0.50796289 -1.25700284  1.13089197  1.13089197 -0.21878771\n  0.71560591 -0.63407376  0.40414137 -0.9455383  -0.21878771 -1.04935982\n -0.21878771 -0.1149662  -1.98375344  0.09267683  1.23471348 -1.56846738\n  0.09267683 -1.04935982 -1.6722889   1.02707045  0.92324894  0.09267683\n  1.02707045  0.92324894  1.33853499  1.23471348 -1.25700284 -0.84171679\n  1.13089197 -1.87993192 -0.9455383   0.40414137 -1.15318133 -0.1149662\n  0.30031986 -0.1149662  -0.01114468 -0.73789528 -0.1149662  -0.84171679\n  0.09267683 -1.25700284 -1.46464587  1.02707045 -1.04935982 -1.15318133\n  0.50796289 -1.15318133 -1.6722889  -0.1149662   1.23471348  0.30031986\n  0.40414137  0.81942743 -0.42643074  1.85764256 -1.36082436 -1.46464587\n -0.84171679  0.50796289 -0.63407376 -0.32260922  0.6117844   0.6117844\n -1.46464587  1.64999953].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Main pipeline - all datasets and models\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random_state=13\n",
    "\n",
    "# Datasets\n",
    "# TODO: credit card frauds dataset features selection\n",
    "for dataset in all_datasets:\n",
    "\n",
    "    X = dataset.loc[:, dataset.columns != \"class\"]#.to_numpy()\n",
    "    y = dataset[\"class\"]#.values\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler().fit(X.to_numpy())\n",
    "    X_arr = scaler.transform(X.to_numpy())\n",
    "    X = pd.DataFrame(X_arr, index=X.index, columns=X.columns)\n",
    "\n",
    "    # Initial train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Classificator models\n",
    "    for model_name in probabilistic_models:\n",
    "        clf_info = get_probabilistic_model(model_name)\n",
    "        Clf = clf_info.get(\"model\")\n",
    "        clf_params_arr = clf_info.get(\"params\")\n",
    "\n",
    "        # Classificator model parameters\n",
    "        for clf_params in clf_params_arr:\n",
    "\n",
    "            # Active learning methods\n",
    "            for method_name in active_learning_methods:\n",
    "                alm_info = get_active_learning_method(method_name)\n",
    "                alm = alm_info.get(\"method\")\n",
    "                alm_params_arr = alm_info.get(\"params\")\n",
    "\n",
    "                # Active learning method parameters\n",
    "                for alm_params in alm_params_arr:\n",
    "                    \n",
    "                    precision_arr = []\n",
    "                    recall_arr = []\n",
    "                    f1_score_arr = []\n",
    "                    auc_pr_curve_arr = [] \n",
    "                    auc_roc_curve_arr = []\n",
    "\n",
    "                    kf = KFold(n_splits=5)\n",
    "                    for kf_train_indices, kf_test_indices in kf.split(X_train):\n",
    "\n",
    "                        X_train_kf, X_test_kf, y_train_kf, y_test_kf = X_train.iloc[kf_train_indices], \\\n",
    "                        X_train.iloc[kf_test_indices], y_train.iloc[kf_train_indices], y_train.iloc[kf_test_indices]\n",
    "                        \n",
    "                        # TODO: for train/pool_sizes = [10, 20, 50, 100]\n",
    "                        pool_size = 0.6\n",
    "                        X_train_init, X_pool, y_train_init, y_pool = train_test_split(X_train_kf, y_train_kf, \\\n",
    "                                                                        test_size=pool_size, random_state=random_state)\n",
    "\n",
    "                        # # TODO: reference model trained on train+pool?\n",
    "                        # X_ref = np.concatenate((X_train, X_pool), axis=0)\n",
    "                        # y_ref = np.concatenate((y_train, y_pool), axis=0)\n",
    "                        \n",
    "                        max_iterations = 10 # TODO: add as a parameter in al method\n",
    "                        precision, recall, f1_score, auc_pr_curve, auc_roc_curve = \\\n",
    "                            learn_active(Clf, clf_params, method_name, alm, alm_params, X_train_init, X_pool, \\\n",
    "                            X_test_kf, y_train_init, y_pool, y_test_kf, max_iterations)\n",
    "                        \n",
    "                        precision_arr.append(precision)\n",
    "                        recall_arr.append(recall)\n",
    "                        f1_score_arr.append(f1_score)\n",
    "                        auc_pr_curve_arr.append(auc_pr_curve) \n",
    "                        auc_roc_curve_arr.append(auc_roc_curve)\n",
    "\n",
    "                    print(50*\"-\"+\"\\n\",\\\n",
    "                        f\"Classificator: {Clf.__name__}\\n\",\\\n",
    "                        f\"Classificator parameters: {clf_params}\\n\",\\\n",
    "                        f\"Active learning method: {alm.__name__}\\n\",\\\n",
    "                        f\"Active leraning parameters: {alm_params}\\n\",\\\n",
    "                        f\"Dataset: {get_variable_name(dataset)[0]}\\n\",\\\n",
    "                        50*\"-\"+\"\\n\", sep='', end='\\n')\n",
    "\n",
    "                    mean_precision = np.mean(precision_arr)\n",
    "                    mean_recall = np.mean(recall_arr)\n",
    "                    mean_f1_score = np.mean(f1_score_arr)\n",
    "                    mean_auc_pr_curve = np.mean(auc_pr_curve_arr)\n",
    "                    mean_auc_roc_curve = np.mean(auc_roc_curve_arr)\n",
    "\n",
    "                    print(f\"Precision: {mean_precision:.2f}\\n\",\\\n",
    "                        f\"Recall: {mean_recall:.2f}\\n\",\\\n",
    "                        f\"F1 score: {mean_f1_score:.2f}\\n\",\\\n",
    "                        f\"Precision-Recall AUC: {mean_auc_pr_curve:.2f}\\n\",\\\n",
    "                        f\"ROC AUC: {mean_auc_roc_curve:.2f}\\n\", sep='', end='\\n')\n",
    "                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Feb 16 2023, 11:54:42) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6bb2103817b8f65d874aa4439dbb8e7554190379943053a192f5cd6f7323878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
